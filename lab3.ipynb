{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32045813",
   "metadata": {},
   "source": [
    "# MNIST Denoising with From-Scratch CNN (NumPy only)\n",
    "\n",
    "This notebook:\n",
    "- Uses the provided `DataGenerator` to load and normalize MNIST.\n",
    "- Adds synthetic noise to images to create a denoising task.\n",
    "- Implements a small fully-convolutional autoencoder **from scratch with NumPy**.\n",
    "- Trains with MSE loss and visualizes denoised outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36acb2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data specification:\n",
      "\tDataset type:           mnist\n",
      "\tNumber of classes:      10\n",
      "\tNumber of channels:     1\n",
      "\tTraining data shape:    (10000, 28, 28, 1)\n",
      "\tValidation data shape:  (6000, 28, 28, 1)\n",
      "\tTest data shape:        (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# 1. Generate data for training and validation\n",
    "from data_generator import DataGenerator\n",
    "\n",
    "dg = DataGenerator(verbose=True)\n",
    "dg.generate(dataset='mnist', N_train=10000, N_valid=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b37be06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN model set up with layers:\n",
      "  Layer 0: conv, W shape: (3, 3, 1, 32)\n",
      "  Layer 1: pool, W shape: None\n",
      "  Layer 2: conv, W shape: (3, 3, 32, 64)\n",
      "  Layer 3: pool, W shape: None\n",
      "  Layer 4: conv, W shape: (3, 3, 64, 64)\n",
      "  Layer 5: pool, W shape: None\n",
      "  Layer 6: upsample, W shape: None\n",
      "  Layer 7: conv, W shape: (3, 3, 64, 64)\n",
      "  Layer 8: upsample, W shape: None\n",
      "  Layer 9: conv, W shape: (3, 3, 64, 32)\n",
      "  Layer 10: conv_out, W shape: (3, 3, 32, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (8,12,12,1) (8,28,28,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# 3. Forward + loss (training loop with backprop will be in the notebook)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfeedforward(x_train[:\u001b[38;5;241m8\u001b[39m])\n\u001b[1;32m---> 15\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(stats)\n",
      "File \u001b[1;32mc:\\Users\\Johanna\\Desktop\\universitetet\\DeepLearning\\lab3\\cnn.py:286\u001b[0m, in \u001b[0;36mCNN.evaluate\u001b[1;34m(self, x, y_true, metric, batch_size, max_val)\u001b[0m\n\u001b[0;32m    283\u001b[0m y_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(y_true)\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 286\u001b[0m     loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean((\u001b[43my_pred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m metric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    288\u001b[0m     loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs(y_pred \u001b[38;5;241m-\u001b[39m y_true))\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (8,12,12,1) (8,28,28,1) "
     ]
    }
   ],
   "source": [
    "from cnn import CNN, init_image_to_image_cnn\n",
    "\n",
    "x_train = dg.x_train  # (N, H, W, C)\n",
    "y_train = dg.x_train  # e.g. identity task; replace with your own target\n",
    "\n",
    "# 2. Model\n",
    "input_shape = x_train.shape[1:]  # (H, W, C)\n",
    "W_list, b_list, lname = init_image_to_image_cnn(input_shape)\n",
    "\n",
    "model = CNN(dataset=dg, verbose=True)\n",
    "model.setup_model(W_list, b_list, lname, activation=\"relu\")\n",
    "\n",
    "# 3. Forward + loss (training loop with backprop will be in the notebook)\n",
    "y_pred = model.feedforward(x_train[:8])\n",
    "stats = model.evaluate(x_train[:8], y_train[:8], metric=\"mse\")\n",
    "print(stats)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
